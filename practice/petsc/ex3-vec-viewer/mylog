Sender: LSF System <lsfadmin@r01n07>
Subject: Job 3689465: <mytest> in cluster <sustchpc> Done

Job <mytest> was submitted from host <login02> by user <mae-weimf> in cluster <sustchpc> at Thu May 12 20:01:07 2022.
Job was executed on host(s) <r01n07>, in queue <ser>, as user <mae-weimf> in cluster <sustchpc> at Thu May 12 20:01:07 2022.
</work/mae-weimf> was used as the home directory.
</work/mae-weimf/practice/petsc/ex3-vec-viewer> was used as the working directory.
Started at Thu May 12 20:01:07 2022.
Terminated at Thu May 12 20:01:08 2022.
Results reported at Thu May 12 20:01:08 2022.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -J mytest
#BSUB -q ser
#BSUB -n 1
#BSUB -W 00:05 
#BSUB -e mylog
#BSUB -o mylog
#BSUB -R "span[ptile=1]"
#BSUB -m "r01n07"


# mpirun -np 2 ./ex2.out
./ex3.out
numactl --hardware


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   0.09 sec.
    Max Memory :                                 4 MB
    Average Memory :                             4.00 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   1 sec.
    Turnaround time :                            1 sec.

The output (if any) follows:

rank [0]: istart = 0 iend = 6 
Vec Object: 1 MPI processes
  type: seq
0.
1.
2.
3.
4.
5.
rank [0]: nlocal = 6 
Vec Object: 1 MPI processes
  type: seq
1.
1.
1.
1.
1.
1.
available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
node 0 size: 97983 MB
node 0 free: 44753 MB
node 1 cpus: 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
node 1 size: 98304 MB
node 1 free: 68498 MB
node distances:
node   0   1 
  0:  10  21 
  1:  21  10 
Sender: LSF System <lsfadmin@r01n07>
Subject: Job 3689477: <mytest> in cluster <sustchpc> Done

Job <mytest> was submitted from host <login02> by user <mae-weimf> in cluster <sustchpc> at Thu May 12 20:03:18 2022.
Job was executed on host(s) <r01n07>, in queue <ser>, as user <mae-weimf> in cluster <sustchpc> at Thu May 12 20:03:18 2022.
</work/mae-weimf> was used as the home directory.
</work/mae-weimf/practice/petsc/ex3-vec-viewer> was used as the working directory.
Started at Thu May 12 20:03:18 2022.
Terminated at Thu May 12 20:03:19 2022.
Results reported at Thu May 12 20:03:19 2022.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -J mytest
#BSUB -q ser
#BSUB -n 1
#BSUB -W 00:05 
#BSUB -e mylog
#BSUB -o mylog
#BSUB -R "span[ptile=1]"
#BSUB -m "r01n07"


mpirun -np 2 ./ex3.out
# ./ex3.out
numactl --hardware


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   0.06 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   0 sec.
    Turnaround time :                            1 sec.

The output (if any) follows:

/work/mae-weimf/.lsbatch/1652356998.3689477.shell:行13: mpirun: 未找到命令
available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
node 0 size: 97983 MB
node 0 free: 52205 MB
node 1 cpus: 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
node 1 size: 98304 MB
node 1 free: 67591 MB
node distances:
node   0   1 
  0:  10  21 
  1:  21  10 
Sender: LSF System <lsfadmin@r01n07>
Subject: Job 3689500: <mytest> in cluster <sustchpc> Done

Job <mytest> was submitted from host <login02> by user <mae-weimf> in cluster <sustchpc> at Thu May 12 20:06:27 2022.
Job was executed on host(s) <r01n07>, in queue <ser>, as user <mae-weimf> in cluster <sustchpc> at Thu May 12 20:06:27 2022.
</work/mae-weimf> was used as the home directory.
</work/mae-weimf/practice/petsc/ex3-vec-viewer> was used as the working directory.
Started at Thu May 12 20:06:27 2022.
Terminated at Thu May 12 20:06:28 2022.
Results reported at Thu May 12 20:06:28 2022.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -J mytest
#BSUB -q ser
#BSUB -n 1
#BSUB -W 00:05 
#BSUB -e mylog
#BSUB -o mylog
#BSUB -R "span[ptile=1]"
#BSUB -m "r01n07"


mpirun -np 2 ./ex3.out
# ./ex3.out
numactl --hardware


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   0.27 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   1 sec.
    Turnaround time :                            1 sec.

The output (if any) follows:

rank [0]: istart = 0 iend = 3 
rank [1]: istart = 3 iend = 6 
Vec Object: 2 MPI processes
  type: mpi
Process [0]
rank [1]: nlocal = 3 
0.
1.
2.
Process [1]
3.
4.
5.
rank [0]: nlocal = 3 
Vec Object: 2 MPI processes
  type: mpi
Process [0]
1.
1.
1.
Process [1]
2.
2.
2.
available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
node 0 size: 97983 MB
node 0 free: 51983 MB
node 1 cpus: 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39
node 1 size: 98304 MB
node 1 free: 66895 MB
node distances:
node   0   1 
  0:  10  21 
  1:  21  10 
